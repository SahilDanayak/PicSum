{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PICSUM- Deployment"
      ],
      "metadata": {
        "id": "znGOg1sItoyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the prerequisite libraries"
      ],
      "metadata": {
        "id": "KEadM1CYt6eu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "961GpfeL31cC",
        "outputId": "68c20d12-9656-4c15-9d3f-be830e96d6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 13 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.35.2)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.98.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.7)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.5.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.16)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install transformers\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "pgXdzCFSOGOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr                               #For using gradio interface\n",
        "from PIL import Image                             #For reading the image\n",
        "import pytesseract                                #Used to read text from image\n",
        "import torch\n",
        "import numpy as np\n",
        "import nltk                                       #Used to download stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance     # Used to find cosine distance between 2 vectors\n",
        "import networkx as nx                             # Used for creating sentence similarity graph\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   device = torch.device(\"cuda\")\n",
        "else:\n",
        "   device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EVKXHPM_8t2",
        "outputId": "0a44b832-4bc2-4b46-871a-fce668f37e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Functions"
      ],
      "metadata": {
        "id": "Ly2l6THc01ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read(filepath):\n",
        "    \"\"\"\n",
        "    Construct a image reading function via pytesseract\n",
        "\n",
        "    Args:\n",
        "        filepath (str)  : The filepath of the image which is to be read\n",
        "    Return:\n",
        "        text (str)      : The text extracted from the image\n",
        "\n",
        "    \"\"\"\n",
        "    return pytesseract.image_to_string(Image.open(filepath))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Returns clean text after preprocessing the image i.e. removing punctuations and extra spaces.\n",
        "\n",
        "    Args:\n",
        "        text (str)      : The text input which has to be cleaned\n",
        "    Return:\n",
        "        sentences (list): A list whose each element is a sentence\n",
        "                          (A sentence is a list of words)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    article = text.split(\".\")\n",
        "    article=[sentence for sentence in article if sentence!=\"\"]                #Removing unnecessary spaces\n",
        "\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        sentence=sentence.replace(\",\", \" , \").replace(\"'\", \" ' \").split(\" \")  #Removing punctuations\n",
        "        sentence=[word for word in sentence if word!=\"\"]                      #Removing empty words\n",
        "        sentences.append(sentence)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def sentence_similarity(sent1, sent2, stopwords):\n",
        "\n",
        "    \"\"\"\n",
        "    Converts words in sentences to one hot encoding format and finds the cosine distance between\n",
        "    the vectors inorder to measure closeness\n",
        "\n",
        "    Args:\n",
        "        sent1 (list)      : A list of string where each string represents a word in sentence\n",
        "        sent2 (list)      : A list of string where each string represents a word in sentence\n",
        "        stopwords (list)  : A list of commonly used words in English Voculbary\n",
        "    Return:\n",
        "        sentences (list): A list whose each element is a sentence\n",
        "                          (A sentence is a list of words)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        "\n",
        "    sent1 = [w.lower() for w in sent1]                        #Converting all words to lower case for uniformity\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "    all_words = list(set(sent1 + sent2))                      #Combining lists and removing duplicates\n",
        "\n",
        "    vector1 = [0] * len(all_words)                            #Converting sentences to vectors\n",
        "    vector2 = [0] * len(all_words)\n",
        "\n",
        "    for w in sent1:                                           #Build the vector for the first sentence\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        "\n",
        "    for w in sent2:                                           #Build the vector for the second sentence\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        "\n",
        "    if np.isnan(1 - cosine_distance(vector1, vector2)):       #If the cosine vector produced nan values\n",
        "        return 0\n",
        "\n",
        "    return 1 - cosine_distance(vector1, vector2)              #Using cosine distance to measure similarity between 2 vectors\n",
        "\n",
        "\n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    \"\"\"\n",
        "    Creates a matrix based on the similarity between 2 sentences\n",
        "\n",
        "    Args:\n",
        "        sentences (list)              : A list of sentence where each sentence represents a string of words\n",
        "        stopwords (list)              : A list of commonly used words in English Voculbary\n",
        "    Return:\n",
        "        similarity_matrix (np.array)  : A 2-D array representing the similarity scores between 2 sentences\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))    #Create an empty similarity matrix\n",
        "\n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2:                                          #Ignore if both are same sentences\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "    # Values closer to 0 have a higher correlation while values closer to 1 have a low correlation\n",
        "\n",
        "def generate_important_sentences(text, top_n=\"auto\"):\n",
        "    \"\"\"\n",
        "    Picking out top_n sentences from the given text\n",
        "\n",
        "    Args:\n",
        "        text  (str)             : The text extracted from the image\n",
        "        top_n (str/int)         : Number of sentences to generate. Default is \"auto\" which generates all\n",
        "                                  possible sentences in order of their priority\n",
        "    Return:\n",
        "        extractive_summarized (str)  : A string denoting the top_n important sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    # Step 1 - Clean text to generate sentences\n",
        "\n",
        "    sentences=clean_text(text)\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.append(\".\")\n",
        "    stop_words.append(\",\")\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank (by scores in descending order) and pick top sentences\n",
        "\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "\n",
        "    if top_n==\"auto\": top_n=len(ranked_sentence)\n",
        "    else: top_n=int(top_n)\n",
        "\n",
        "    for i in range(top_n):\n",
        "      ranked_sentence[i][1][0]=ranked_sentence[i][1][0].capitalize()    #Capitalising 1st letter of sentence\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarized text\n",
        "\n",
        "    extractive_summarized=\". \".join(summarize_text).replace(\" , \",\", \").replace(\" ' \",\"'\") + \".\"\n",
        "    return extractive_summarized\n",
        "\n",
        "def important_sentences(filepath, no_of_sentences=5):\n",
        "    \"\"\"\n",
        "    Picking out no_of_sentences from the given text and displaying them inoder\n",
        "\n",
        "    Args:\n",
        "        filepath (str)              : The filepath of the image which is to be read\n",
        "        no_of_sentences (int)       : Number of sentences to generate. Default is 5\n",
        "    Return:\n",
        "        tuple                       : Gradio commands to print output\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    extractedInformation=read(filepath)                                   #reading the information from filepath\n",
        "    extractedInformation=' '.join(extractedInformation.split('\\n'))\n",
        "\n",
        "    try:                                                                  #if the text can generate 5 sentences\n",
        "      extractive_summary=generate_important_sentences(extractedInformation, no_of_sentences)\n",
        "    except:                                                               #if not enough information, generate max possible number of sentences\n",
        "      extractive_summary=generate_important_sentences(extractedInformation,\"auto\")\n",
        "\n",
        "    text=\"\"\n",
        "    for index,sent in enumerate(extractive_summary.split(\".\")):\n",
        "      if sent!='':text+=str(index+1)+\". \"+str(sent).strip()+\".\\n\\n\"\n",
        "    return (gr.Textbox.update(text),gr.Button.update(visible=False),gr.Textbox.update(visible=False),gr.Dropdown.update(visible=False))\n",
        "\n",
        "def summarize(filepath):\n",
        "    \"\"\"\n",
        "    Summarize the information from image\n",
        "\n",
        "    Args:\n",
        "        filepath (str)              : The filepath of the image which is to be read\n",
        "    Return:\n",
        "        tuple                       : Gradio commands to print output\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    extractedInformation=read(filepath)                                  #extracting information from filepath\n",
        "    extractedInformation=' '.join(extractedInformation.split('\\n'))\n",
        "                                                                          #generating an abstractive summary with dynamic length\n",
        "    abstractive_summary = summarizer(extractedInformation, max_length=int(len(extractedInformation)/6), min_length=int(len(extractedInformation)/10), do_sample=False)\n",
        "    return (gr.Textbox.update(abstractive_summary[0][\"summary_text\"]),gr.Button.update(visible=False),gr.Textbox.update(visible=False),gr.Dropdown.update(visible=False))\n",
        "\n",
        "def Question_Answer(filepath,question,mode):\n",
        "    \"\"\"\n",
        "    Generate question answer from the given context\n",
        "\n",
        "    Args:\n",
        "        filepath (str)              : The filepath of the image which is to be read\n",
        "        question (str)              : The question to be answered\n",
        "        mode (str)                  : Whether Roberta model to use or distilbert\n",
        "    Return:\n",
        "        tuple                       : Gradio commands to print output\n",
        "\n",
        "    \"\"\"\n",
        "    extractedInformation=read(filepath)\n",
        "    extractedInformation=' '.join(extractedInformation.split('\\n'))\n",
        "    if mode==\"Roberta\":\n",
        "      question_answerer = pipeline(\"question-answering\", model=\"SMD00/QA_model-roberta\")\n",
        "    else :\n",
        "      question_answerer = pipeline(\"question-answering\", model=\"SMD00/QA_model-distilbert\")\n",
        "    obj=question_answerer(question=question, context=extractedInformation)\n",
        "    return obj['answer']\n"
      ],
      "metadata": {
        "id": "qGN_mzGVjOBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Gradio Interface"
      ],
      "metadata": {
        "id": "utu_p8Dy05cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_fn():\n",
        "  return (gr.Textbox.update(visible=True),gr.Button.update(visible=True),gr.Dropdown.update(visible=True),gr.Textbox.update(\"\"))\n",
        "def dummy_fn(x):\n",
        "  return x\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# **PicSum**\")\n",
        "    gr.Markdown(\"Gradio demo for PicSum project. You can give an image as input and select any of the three buttons. It generates summary, important sentences and answers questions related to context.\")\n",
        "    img=gr.components.Image(type=\"filepath\", label=\"Input Image\")\n",
        "\n",
        "    with gr.Row():\n",
        "        summary_btn = gr.Button(value=\"Summary\")\n",
        "        sentence_btn = gr.Button(value=\"Important Sentences\")\n",
        "        quesAndAns_btn = gr.Button(value=\"Question and Answers\")\n",
        "\n",
        "    mode=gr.Dropdown([\"Roberta\",\"DistilBert\"],label=\"Model\",info=\"Choose a model\",visible=False)\n",
        "    ques_box = gr.Textbox(label=\"Question\",info=\"Enter a Question\",interactive=True,visible=False)\n",
        "    submit_btn= gr.Button(value=\"Submit\",visible=False)\n",
        "    out_box=gr.Textbox(label=\"Generated Text\")\n",
        "    summary_btn.click(fn=summarize,inputs=[img],outputs=[out_box,submit_btn,ques_box,mode])\n",
        "    sentence_btn.click(fn=important_sentences,inputs=[img],outputs=[out_box,submit_btn,ques_box,mode])\n",
        "    quesAndAns_btn.click(fn=show_fn,outputs=[submit_btn,ques_box,mode,out_box])\n",
        "    submit_btn.click(fn=Question_Answer,inputs=[img,ques_box,mode],outputs=[out_box])\n",
        "    gr.Markdown(\"## Image Examples\")\n",
        "    with gr.Row():\n",
        "        gr.Examples(\n",
        "            examples=[ \"/content/a.png\"],\n",
        "            inputs=img,\n",
        "            outputs=img,\n",
        "            fn=dummy_fn,\n",
        "            cache_examples=True,\n",
        "        )\n",
        "        gr.Examples(\n",
        "            examples=[ \"/content/b.png\"],\n",
        "            inputs=img,\n",
        "            outputs=img,\n",
        "            fn=dummy_fn,\n",
        "            cache_examples=True,\n",
        "        )\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "6pV1BfFcm6qA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "fb0347dd-bb43-472c-b199-49e56417ce9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:261: UserWarning: api_name load_example already exists, using load_example_1\n",
            "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cache from '/content/gradio_cached_examples/14' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Using cache from '/content/gradio_cached_examples/15' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}